{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.8.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "# 기본\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 경고 뜨지 않게 설정\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 그래프 설정\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "# plt.rcParams['font.family'] = 'AppleGothic'\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['figure.figsize'] = 20, 10\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 데이터 전처리 알고리즘\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 학습용과 검증용으로 나누는 함수\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 교차 검증\n",
    "# 지표를 하나만 설정할 경우\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# 지표를 하나 이상 설정할 경우\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# 모델의 최적의 하이퍼파라미터를 찾기 위한 도구\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 평가함수\n",
    "# 분류용\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# 회귀용\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 머신러닝 알고리즘 - 분류\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# 머신러닝 알고리즘 - 회귀\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "# 차원축소\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# 군집화\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.cluster import estimate_bandwidth\n",
    "\n",
    "# ARIMA (시계열 예측)\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# 시간 측정을 위한 시간 모듈\n",
    "import datetime\n",
    "# 주식 정보를 읽어오기 위한 라이브러리\n",
    "from pandas_datareader import data\n",
    "\n",
    "# 형태소 백터를 생성하기 위한 라이브러리\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# 형태소 백터를 학습 백터로 변환한다.\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# 데이터 수집\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "\n",
    "# 한국어 형태소 분석\n",
    "from konlpy.tag import Okt, Hannanum, Kkma, Mecab, Komoran\n",
    "\n",
    "# 워드 클라우드를 위한 라이브러리\n",
    "from collections import Counter\n",
    "import pytagcloud\n",
    "from IPython.display import Image\n",
    "\n",
    "# 출력 창 청소를 위한 함수\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# 저장\n",
    "import pickle\n",
    "\n",
    "# 딥러닝\n",
    "import tensorflow as tf\n",
    "\n",
    "# 딥러닝 모델 구조를 정의하는 것\n",
    "from tensorflow.keras.models import Sequential\n",
    "# 층구조를 정의하는 것\n",
    "from tensorflow.keras.layers import Dense\n",
    "# 활성화 함수를 정의하는 것\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "# 다중 분류를 위한 원핫 인코딩\n",
    "# 결과데이터의 종류 수 만큼 결과데이터의 컬럼을 늘리는 작업\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 현재 프로젝트를 gpu에 할당한다.\n",
    "# 컴퓨터의 GPU는 메모리를 가지고 있다.\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# gpu가 있다면..\n",
    "if len(gpus) > 0 :\n",
    "    try :\n",
    "        for gpu in gpus :\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e :\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 설정\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   R  \n",
       "1  0.0052  0.0044   R  \n",
       "2  0.0095  0.0078   R  \n",
       "3  0.0040  0.0117   R  \n",
       "4  0.0107  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터를 읽어온다.\n",
    "df1 = pd.read_csv('data/sonar.csv', header=None)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.1694</td>\n",
       "      <td>0.2328</td>\n",
       "      <td>0.2684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.1178</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.1123</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1843</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "0    0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n",
       "204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n",
       "205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n",
       "206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n",
       "207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n",
       "\n",
       "         9   ...      50      51      52      53      54      55      56  \\\n",
       "0    0.2111  ...  0.0232  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180   \n",
       "1    0.2872  ...  0.0125  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140   \n",
       "2    0.6194  ...  0.0033  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316   \n",
       "3    0.1264  ...  0.0241  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050   \n",
       "4    0.4459  ...  0.0156  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072   \n",
       "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.2684  ...  0.0203  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065   \n",
       "204  0.2154  ...  0.0051  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034   \n",
       "205  0.2529  ...  0.0155  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140   \n",
       "206  0.2354  ...  0.0042  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034   \n",
       "207  0.2354  ...  0.0181  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040   \n",
       "\n",
       "         57      58      59  \n",
       "0    0.0084  0.0090  0.0032  \n",
       "1    0.0049  0.0052  0.0044  \n",
       "2    0.0164  0.0095  0.0078  \n",
       "3    0.0044  0.0040  0.0117  \n",
       "4    0.0048  0.0107  0.0094  \n",
       "..      ...     ...     ...  \n",
       "203  0.0115  0.0193  0.0157  \n",
       "204  0.0032  0.0062  0.0067  \n",
       "205  0.0138  0.0077  0.0031  \n",
       "206  0.0079  0.0036  0.0048  \n",
       "207  0.0036  0.0061  0.0115  \n",
       "\n",
       "[208 rows x 60 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0      R\n",
       "1      R\n",
       "2      R\n",
       "3      R\n",
       "4      R\n",
       "      ..\n",
       "203    M\n",
       "204    M\n",
       "205    M\n",
       "206    M\n",
       "207    M\n",
       "Name: 60, Length: 208, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 입력과 결과로 나눈다.\n",
    "X = df1.drop(60, axis=1)\n",
    "y = df1[60]\n",
    "\n",
    "display(X)\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문자열 변환\n",
    "encoder1 = LabelEncoder()\n",
    "encoder1.fit(y)\n",
    "y = encoder1.transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFold 생성\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 112ms/step - loss: 0.6706 - accuracy: 0.8095\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.7617 - accuracy: 0.8095\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.0714 - accuracy: 0.8095\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.1710 - accuracy: 0.8095\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x00000162985385E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1518 - accuracy: 0.9048\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x00000162B5410040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9210 - accuracy: 0.8095\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7594 - accuracy: 0.8095\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6441 - accuracy: 0.8571\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.1261 - accuracy: 0.9000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.8363 - accuracy: 0.8500\n",
      "[0.8095238208770752, 0.8095238208770752, 0.8095238208770752, 0.8095238208770752, 0.9047619104385376, 0.8095238208770752, 0.8095238208770752, 0.8571428656578064, 0.8999999761581421, 0.8500000238418579]\n"
     ]
    }
   ],
   "source": [
    "# 예측 정확도를 담을 리스트\n",
    "result_list = []\n",
    "\n",
    "# 폴드의 수 만큼 반복한다.\n",
    "for train_idx, test_idx in kfold.split(X) :\n",
    "    # 모델 설정\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(24, input_dim=60))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    # 모델 컴파일\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # 학습한다.\n",
    "    model.fit(X.loc[train_idx], y[train_idx], epochs=200, batch_size=5, verbose=0)\n",
    "    \n",
    "    # 검증\n",
    "    r1 = model.evaluate(X.loc[test_idx], y[test_idx])\n",
    "    result_list.append(r1[1])\n",
    "    \n",
    "print(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 성능 그래프\n",
    "plt.plot(result_list)\n",
    "plt.ylim(0, 1.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
